from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import AgentExecutor, create_react_agent, tool

from langchain_core.runnables import Runnable
from langchain_core.messages import AIMessage, HumanMessage, AnyMessage

from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

from typing import Annotated, Dict, Optional
from typing_extensions import TypedDict

from dotenv import load_dotenv

from RAG import RAG
from ReActAgent import ReActAgent

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° LLM ì •ì˜
load_dotenv()
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# ğŸ“¦ LangGraph ìƒíƒœ ì •ì˜
class GraphState(TypedDict):
    input: Annotated[list, add_messages]
    health: Optional[str] = None
    menus: Optional[str] = None
    web: Optional[str] = None
    reply: Optional[str] = None

# ğŸ”§ ReAct Agent Node
def react_agent_node(state: GraphState) -> Dict:
    print("state", state)
    react_agent = ReActAgent()
    result = react_agent.run(state["input"])
    print("result", result)
    # result = react_agent_executor.invoke({"input": state["input"]})
    
    health = None
    menus = None
    web = None

    # resultëŠ” dict, 'output' í•„ë“œì— ìµœì¢… ë‹µë³€ ìˆìŒ
    if "health" in str(result):
        health = result["health"]
    if "menus" in str(result):
        menus = result["menus"]
    if "web" in str(result):
        web = result["web"]

    return {
        "health": health,
        "menus": menus,
        "web": web,
        "reply": result["output"] if isinstance(result, dict) and "output" in result else str(result),
    }

# ğŸ’¬ LLM Chat Node (ê²°ê³¼ë¥¼ ì¬ì •ë¦¬í•˜ê±°ë‚˜ ìš”ì•½ ê°€ëŠ¥)
def chat_node(state: GraphState) -> Dict:
    print("chat_node - state", state)
    messages = [
        HumanMessage(content=f"""
        ì•„ë˜ëŠ” ë„êµ¬ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ì •ë³´ì•¼. ì´ê±¸ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìì—°ìŠ¤ëŸ¬ìš´ í˜•íƒœë¡œ ëŒ€ë‹µí•´ì¤˜.

        ê±´ê°• ì •ë³´: {state["health"]}
        ì¶”ì²œ ë©”ë‰´: {state["menus"]}
        ì›¹ ê²€ìƒ‰ ê²°ê³¼: {state["web"]}
        """)
    ]
    response = llm.invoke({"input": messages})
    return {"reply": response.content.strip()}

# ğŸŒ LangGraph êµ¬ì„±
graph_builder = StateGraph(GraphState)

graph_builder.add_node("react_agent_node", react_agent_node)
graph_builder.add_node("chat_node", chat_node)

# ì—£ì§€ ì •ì˜
graph_builder.set_entry_point("react_agent_node")
graph_builder.add_edge("react_agent_node", "chat_node")
graph_builder.add_edge("chat_node", END)

# Graph ì™„ì„±
graph = graph_builder.compile()
print("graph", graph)
# display(Image(graph.get_graph().draw_mermaid_png()))

def chat(user_message):
    final_state = graph.invoke({"input": [HumanMessage(content=user_message)]})
    # final_state = graph.invoke({"input": user_message})

    # final_state = graph.invoke(user_message)
    # final_state = graph.invoke([HumanMessage(user_message)])
    print("final_state", final_state)


# chat("ë‚˜ ì•Œë ˆë¥´ê¸° ë•Œë¬¸ì¸ì§€ í”¼ë¶€ê°€ ê°€ë ¤ì›Œ")